{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evaluating classifier results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_results import get_score_df, load_histo_file\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "source": [
    "Paths to result files. These can be downloaded from the results folder in the project Drive folder.\n",
    "\n",
    "If you have a different set of results, you'll want to replace these values. Then the rest of the notebook should run fine."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATHS: List[str] = [\n",
    "    \"N_east_all.csv\",\n",
    "    \"N_se_h1-cc80.csv\",\n",
    "    \"indonesia_1_0200.csv\",\n",
    "    \"indonesia_2_200.csv\",\n",
    "    \"indonesia_2_180.csv\"\n",
    "]\n",
    "RESULTS_DIR = \"results/\""
   ]
  },
  {
   "source": [
    "Load results, expecting them to be of the form as the files listed above, in a direc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {path: load_histo_file(RESULTS_DIR + path) for path in RESULTS_PATHS}"
   ]
  },
  {
   "source": [
    "Now we merge the visual interpretation data in. This requires you to have the data at the appropriate path. Again, this data file can be downloaded from Drive, this time from the labels directory.\n",
    "\n",
    "Alternatively, you can create the relevant CSVs yourself from the xlsx files provided by the client by running the scripts `xlsx_to_csv.py` and `train_test_split.py` successively.\n",
    "\n",
    "**NB: We specifically use \"training_complete.csv\" because the test data is intended to be reserved only for evaluation of the system at the end of the project.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/onniaarn/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(\"label_CSVs/training_complete.csv\")\n",
    "\n",
    "results_w_labels = dict()\n",
    "for path, df in results.items():\n",
    "    results_w_labels[path] = pd.merge(df, labels_df, how=\"inner\", left_on=\"plotID\",right_on=\"pl_plotid\")\n"
   ]
  },
  {
   "source": [
    "The block below prints the mean absolute errors of the different results files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                              MAE  Avg. actual  Avg. predicted\n% Forest Loss 2000-2010  0.143885     0.143885             0.0\n% Forest Loss 2010-2018  1.258993     1.258993             0.0\n                            MAE  Avg. actual  Avg. predicted\n% Forest Loss 2000-2010  9.6875       9.6875             0.0\n% Forest Loss 2010-2018  1.5625       1.5625             0.0\n                               MAE  Avg. actual  Avg. predicted\n% Forest Loss 2000-2010  13.427741    13.333333        0.124469\n% Forest Loss 2010-2018   3.089978     3.083333        0.006645\n                               MAE  Avg. actual  Avg. predicted\n% Forest Loss 2000-2010  37.376412      37.3750        0.001412\n% Forest Loss 2010-2018   5.062500       5.0625        0.000000\n                               MAE  Avg. actual  Avg. predicted\n% Forest Loss 2000-2010  25.702330    26.074074        0.371744\n% Forest Loss 2010-2018   6.518519     6.518519        0.000000\n"
     ]
    }
   ],
   "source": [
    "for path, df in results_w_labels.items():\n",
    "    print(get_score_df(df))"
   ]
  },
  {
   "source": [
    "## Saving the cleaned data\n",
    "\n",
    "If you wish, you can run the block below to save the processessed results files with the proper percentages as CSVs. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DIR = \"cleaned_results/\"\n",
    "\n",
    "if not os.path.exists(CLEAN_DIR):\n",
    "    os.mkdir(CLEAN_DIR)\n",
    "\n",
    "for path, df in results_w_labels.items():\n",
    "    df.to_csv(CLEAN_DIR + path)"
   ]
  },
  {
   "source": [
    "## Stuff to be added\n",
    "\n",
    "- What fraction deforestation was missed?\n",
    "- Visualizations of where and how the model goes wrong"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}