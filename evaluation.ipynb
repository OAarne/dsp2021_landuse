{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evaluating classifier results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_results import get_score_df, load_histo_file\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml"
   ]
  },
  {
   "source": [
    "Results files are loaded from paths specified in `config.yaml`. See `example_config.yaml` for an example of how this should be structured. The results files themselves can be downloaded from the shared results folder on Google Drive."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    RESULTS_DIR = config[\"results_dir\"]\n",
    "    RESULTS_PATHS = config[\"results_files\"]"
   ]
  },
  {
   "source": [
    "Load results, expecting them to be of the form as the files listed above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {filename: load_histo_file(os.path.join(RESULTS_DIR, filename)) for filename in RESULTS_PATHS}"
   ]
  },
  {
   "source": [
    "Now we merge the visual interpretation data in. This requires you to have the data at the appropriate path. Again, this data file can be downloaded from Drive, this time from the labels directory.\n",
    "\n",
    "Alternatively, you can create the relevant CSVs yourself from the xlsx files provided by the client by running the scripts `xlsx_to_csv.py` and `validation_test_split.py` successively.\n",
    "\n",
    "**NB: We specifically use \"validation_complete.csv\" because the test data is intended to be reserved only for evaluation of the system at the end of the project.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"label_CSVs/validation_complete.csv\")\n",
    "\n",
    "# Here we remove any lines corresponding to unstocked forest (as of 2018), because one cannot reliably determine tree cover from land use in those cases.\n",
    "print(labels_df.shape)\n",
    "\n",
    "labels_df = labels_df.loc[\n",
    "    (\n",
    "        labels_df[\"Sub-Categories if Naturally regenerated forest\"]\n",
    "        != \"Temporarily unstocked forest\"\n",
    "    )\n",
    "    & (\n",
    "        labels_df[\"Sub-Categories if Planted forest\"]\n",
    "        != \"Temporarily unstocked planted forest\"\n",
    "    ),\n",
    "    :,\n",
    "]\n",
    "\n",
    "print(labels_df.shape)\n",
    "\n",
    "results_w_labels = dict()\n",
    "for path, df in results.items():\n",
    "    results_w_labels[path] = pd.merge(df, labels_df, how=\"inner\", left_on=\"plotID\",right_on=\"pl_plotid\")\n"
   ]
  },
  {
   "source": [
    "The block below prints the mean absolute errors, precision, recall, etc. of the different results files.\n",
    "\n",
    "Precision and recall are calculated while treating the model as a binary forest loss or forest gain detector.\n",
    "\n",
    "The F-5.0 column refers to an [$F_\\beta$ score](https://en.wikipedia.org/wiki/F-score) with $\\beta=5$. The score unifies precision and recall into a single metric. The value of $\\beta$ determines how many times more important recall is compared to precision. If you wish to use a different beta, you can pass it to `get_score_df` using the keyword arguent `beta`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, df in results_w_labels.items():\n",
    "    print(path)\n",
    "    print(get_score_df(df))"
   ]
  },
  {
   "source": [
    "## Saving the cleaned data\n",
    "\n",
    "If you wish, you can run the block below to save the processessed results files with the proper percentages as CSVs. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DIR = \"cleaned_results/\"\n",
    "\n",
    "if not os.path.exists(CLEAN_DIR):\n",
    "    os.mkdir(CLEAN_DIR)\n",
    "\n",
    "for path, df in results_w_labels.items():\n",
    "    df.to_csv(CLEAN_DIR + path)"
   ]
  },
  {
   "source": [
    "## Visualizing results\n",
    "\n",
    "If you get an error like `UserWarning: 38.3% of the points cannot be placed` with the swarmplots, just decrease the value of the `size` parameter passed to the `sns.swarmplot` function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat(results_w_labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score_df(total_df)"
   ]
  },
  {
   "source": [
    "## Plotting deforestation\n",
    "\n",
    "First, we plot actual deforestation against deforestation according to the visual interpreters. For clarity, hexas for which there was no deforestation according to the visual interpreters are visualized separately as a histogram below.\n",
    "\n",
    "You may want to adjust the definition of `df` below to match whatever set of results you wish to visualize."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_df\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "fig.set_size_inches(18.5, 8)\n",
    "w_change_2000 = total_df.loc[total_df[\"% Forest Loss 2000-2010\"] >= 10, :]\n",
    "w_change_2010 = total_df.loc[total_df[\"% Forest Loss 2010-2018\"] >= 10, :]\n",
    "sns.swarmplot(x=w_change_2000[\"% Forest Loss 2000-2010\"], y=w_change_2000[\"deforestation 2000-2010\"], size=2, ax=axes[0])\n",
    "axes[0].set_ylabel(\"Predicted deforestation % 2000-2010\")\n",
    "axes[0].set_xlabel(\"Actual deforestation % 2000-2010\")\n",
    "sns.swarmplot(x=w_change_2010[\"% Forest Loss 2010-2018\"], y=w_change_2010[\"deforestation 2010-2018\"], size=2, ax=axes[1])\n",
    "axes[1].set_ylabel(\"Predicted deforestation % 2010-2018\")\n",
    "axes[1].set_xlabel(\"Actual deforestation % 2010-2018\")\n",
    "fig.suptitle(\"Actual vs predicted deforestation for all hexas where there was deforestation\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_change_2000.shape)\n",
    "print(w_change_2010.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_df\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "fig.set_size_inches(18.5, 8)\n",
    "w_no_change_2000 = total_df.loc[total_df[\"% Forest Loss 2000-2010\"] < 10, :]\n",
    "w_no_change_2010 = total_df.loc[total_df[\"% Forest Loss 2010-2018\"] < 10, :]\n",
    "sns.histplot(y=w_no_change_2000[\"deforestation 2000-2010\"], ax=axes[0], bins=20)\n",
    "sns.histplot(y=w_no_change_2010[\"deforestation 2010-2018\"], ax=axes[1], bins=20)\n",
    "x_lim = max(axes[0].get_xlim(), axes[1].get_xlim())\n",
    "y_lim = (0, 100)\n",
    "axes[0].set_xlim(x_lim)\n",
    "axes[0].set_ylim(y_lim)\n",
    "axes[1].set_xlim(x_lim)\n",
    "axes[1].set_ylim(y_lim)\n",
    "axes[0].set_ylabel(\"Predicted deforestation % 2000-2010\")\n",
    "axes[1].set_ylabel(\"Predicted deforestation % 2010-2018\")\n",
    "fig.suptitle(\"Histogram of predictions for hexas where there was no actual deforestation\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Both the swarm plot and histogram of one time period, in one figure:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = \"2010-2018\"\n",
    "\n",
    "df = total_df\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "fig.set_size_inches(18, 9)\n",
    "w_no_change = total_df.loc[total_df[\"% Forest Loss \" + period] < 10, :]\n",
    "w_change = total_df.loc[total_df[\"% Forest Loss \" + period] >= 10, :]\n",
    "sns.swarmplot(x=w_change[\"% Forest Loss \" + period], y=w_change[\"deforestation \" + period], size=2, ax=axes[0])\n",
    "sns.histplot(y=w_no_change[\"deforestation \" + period], ax=axes[1], bins=50)\n",
    "y_lim = (0, 100)\n",
    "axes[0].set_ylim(y_lim)\n",
    "axes[1].set_ylim(y_lim)\n",
    "axes[0].set_ylabel(\"Predicted deforestation % \" + period, fontsize=14)\n",
    "axes[1].set_ylabel(\"Predicted deforestation % \" + period, fontsize=14)\n",
    "axes[0].set_xlabel(\"Actual deforestation % \" + period, fontsize=14)\n",
    "axes[1].set_xlabel(\"Count\", fontsize=14)\n",
    "axes[0].set_title(\"Actual vs predicted deforestation for all hexas where there was deforestation\", fontsize=16)\n",
    "axes[1].set_title(\"Histogram of predictions for hexas where there was no actual deforestation\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Visualizing amount of forest cover in 2018"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2010\"\n",
    "\n",
    "df = total_df\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18.5, 8)\n",
    "sns.swarmplot(x=df[\"% of Forest\"], y=df[\"forest \" + year], size=3, ax=ax)\n",
    "ax.set_ylabel(\"Predicted forest % \" + year)\n",
    "ax.set_xlabel(\"Actual forest % \" + year)\n",
    "fig.suptitle(\"Actual vs predicted forest cover for all hexas\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ]
}